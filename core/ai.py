from openai import OpenAI
from django.conf import settings

from django.contrib.auth.models import User
from .models import Task, Profile, EmployeeSkill, Skill
import json
import re

# Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ÙƒÙ„Ø§ÙŠÙ†Øª Ù…Ø±Ø© ÙˆØ­Ø¯Ø©
client = OpenAI(api_key=settings.OPENAI_API_KEY)

def _map_workload_impact_value(impact_code: str | None) -> int:
    """
    ÙŠØ­ÙˆÙ‘Ù„ ÙƒÙˆØ¯ ØªØ£Ø«ÙŠØ± Ø§Ù„Ù…Ù‡Ù…Ø© Ø¥Ù„Ù‰ Ø±Ù‚Ù…:
    normal â†’ 1, medium â†’ 2, heavy â†’ 3
    """
    if impact_code is None:
        return 1
    mapping = {
        "normal": 1,   # Ø¹Ø§Ø¯ÙŠØ©
        "medium": 2,   # Ù…ØªÙˆØ³Ø·Ø©
        "heavy": 3,    # Ø«Ù‚ÙŠÙ„Ø©
    }
    return mapping.get(impact_code, 1)


def _extract_text_from_response(response) -> str:
    """
    Ø¯Ø§Ù„Ø© Ù…Ø³Ø§Ø¹Ø¯Ø© Ø¹Ø´Ø§Ù† Ù†Ø·Ù„Ø¹ Ø§Ù„Ù†Øµ Ù…Ù† response Ø­Ù‚ OpenAI
    Ø¨Ø¯ÙˆÙ† Ù…Ø§ Ù†ØªØ¹Ù‚Ù‘Ø¯ Ù„Ùˆ ØªØºÙŠØ± Ø§Ù„Ø´ÙƒÙ„ Ø´ÙˆÙŠ.
    """
    out = response.output[0].content[0]
    text = getattr(out, "text", out)
    text = getattr(text, "value", str(text))
    return text


def chat_with_stad_ai(message: str) -> str:
    """
    Ø¯Ø§Ù„Ø© Ø¨Ø³ÙŠØ·Ø© Ù‚Ø¯ÙŠÙ…Ø© (Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø±) ØªØ±Ø³Ù„ Ø¨Ø±ÙˆÙ…Ø¨Øª Ù„Ù€ OpenAI ÙˆØªØ±Ø¬Ø¹ Ø±Ø¯ Ø¹Ø§Ø¯ÙŠ.
    ØªØ³ØªØ®Ø¯Ù… ÙÙŠ test_ai_view.
    """
    try:
        response = client.responses.create(
            model="gpt-4.1-mini",
            input=message,
        )
        reply_text = _extract_text_from_response(response)
        return reply_text
    except Exception as e:
        return f"ERROR from OpenAI: {e}"


# ==============================
# 1) Ø¨Ù†Ø§Ø¡ JSON Ù…Ù† Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù†Ø¸Ø§Ù…
# ==============================

def build_candidates_list():
    """
    ØªØ±Ø¬Ø¹ Ù‚Ø§Ø¦Ù…Ø© ÙƒÙ„ Ø§Ù„Ù…ÙˆØ¸ÙÙŠÙ† Ù…Ø¹ Ø¨ÙŠØ§Ù†Ø§ØªÙ‡Ù… Ø§Ù„Ù„ÙŠ Ù†Ø³ØªØ®Ø¯Ù…Ù‡Ø§ ÙÙŠ Ø§Ù„ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø°ÙƒÙŠ:
    - Ø§Ù„Ù…Ù‡Ø§Ø±Ø§Øª
    - Ø§Ù„Ù…Ø³Ù…Ù‰ Ø§Ù„ÙˆØ¸ÙŠÙÙŠ
    - Ø§Ù„ØµÙ„Ø§Ø­ÙŠØ§Øª Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬Ø© Ù…Ù† Ø§Ù„Ù€ job_role
    """
    profiles = (
        Profile.objects
        .filter(role="employee")
        .select_related("user", "job_role")
        .prefetch_related("user__skill_set__skill", "job_role__permissions")
    )

    candidates = []
    for profile in profiles:
        user = profile.user

        # âœ… Ù…Ù‡Ø§Ø±Ø§Øª Ø§Ù„Ù…ÙˆØ¸Ù
        skills = [
            {
                "skill_id": es.skill.id,
                "skill_name": es.skill.name,
                "level": es.level,
            }
            for es in user.skill_set.all()
        ]

        # âœ… ØµÙ„Ø§Ø­ÙŠØ§Øª Ø§Ù„ÙˆØ¸ÙŠÙØ© (job_role.permissions)
        permissions = []
        if profile.job_role:
            permissions = [
                perm.name for perm in profile.job_role.permissions.all()
            ]

        candidates.append(
            {
                "user_id": user.id,
                "name": user.get_full_name() or user.username,
                "job_role": profile.job_role.name if profile.job_role else None,
                "permissions": permissions,          # ğŸ‘ˆ Ù…Ø¶Ø§ÙØ© Ø¬Ø¯ÙŠØ¯Ø©
                "current_workload": profile.current_workload,
                "overall_rating": profile.overall_rating,
                "rating_count": profile.rating_count,
                "skills": skills,
            }
        )

    print("\n\nCANDIDATES DEBUG OUTPUT:\n", json.dumps(candidates, ensure_ascii=False, indent=2), "\n\n")
    return candidates




def build_task_context(task: Task) -> dict:
    """
    ØªØ³ØªØ®Ø¯Ù… Ù„Ù…Ø§ ØªÙƒÙˆÙ† Ø§Ù„Ù…Ù‡Ù…Ø© Ù…Ø­ÙÙˆØ¸Ø© ÙÙŠ Ø§Ù„Ø¯Ø§ØªØ§Ø¨ÙŠØ³.
    ØªØ¨Ù†ÙŠ JSON ÙÙŠÙ‡:
    - Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…Ù‡Ù…Ø©
    - Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù…Ø±Ø´Ø­ÙŠÙ† (Ù…Ù† build_candidates_list)
    """
    required_skills = [
        {"id": s.id, "name": s.name}
        for s in task.required_skills.all()
    ]

    impact_value = _map_workload_impact_value(getattr(task, "impact", None))

    context = {
        "task": {
            "id": task.id,
            "title": task.title,
            "description": task.description,
            "project": task.project.name if task.project else None,
            "due_date": task.due_date.isoformat() if task.due_date else None,
            "required_skills": required_skills,
            "priority": getattr(task, "priority", "medium"),  
            "workload_impact_value": impact_value, 
        },
        "candidates": build_candidates_list(),  # âœ… Ù‡Ù†Ø§ Ø§Ø³ØªØ®Ø¯Ù…Ù†Ø§ Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©
    }

    return context



def debug_task_context(task: Task):
    """
    Ø¯Ø§Ù„Ø© Ø¨Ø³ ØªØ·Ø¨Ø¹ JSON ÙÙŠ Ø§Ù„ÙƒÙˆÙ†Ø³Ù„ Ø¹Ø´Ø§Ù† ØªØ´ÙˆÙ Ø´ÙƒÙ„Ù‡ Ù‚Ø¨Ù„ Ø±Ø¨Ø· AI.
    ØªÙ‚Ø¯Ø± ØªØ³ØªØ¯Ø¹ÙŠÙ‡Ø§ Ù…Ù† Django shell.
    """
    ctx = build_task_context(task)
    print(json.dumps(ctx, ensure_ascii=False, indent=2))


# ==============================
# 2) Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ© STAD Ù…Ø¹ OpenAI
# ==============================

def _call_stad_ai_assignment(context: dict) -> dict:
    """
    ØªØ³ØªÙ‚Ø¨Ù„ context (task + candidates) ÙˆØªØ±Ø³Ù„Ù‡Ø§ Ù„Ù€ OpenAI
    ÙˆØªØ±Ø¬Ø¹ JSON ÙÙŠÙ‡ assigned_user_id + reason + scores.
    ØªØ³ØªØ®Ø¯Ù…Ù‡Ø§ Ø£ÙƒØ«Ø± Ù…Ù† Ø¯Ø§Ù„Ø© (Ù…Ù† Ù†Ù…ÙˆØ°Ø¬ Ø­Ù‚ÙŠÙ‚ÙŠ Ø£Ùˆ Ù…Ù† ÙÙˆØ±Ù…).
    """
    system_prompt = """
You are STAD, an AI agent that assigns tasks to employees in a company.

You receive a JSON object with:
{
  "task": {
    "id": int or null,
    "title": str,
    "description": str,
    "project": str or null,
    "due_date": ISO date string or null,
    "required_skills": [
      {"id": int, "name": str}
    ],
    "priority": "low" | "medium" | "high",
    "workload_impact_value": int   // 1 (normal), 2 (medium), 3 (heavy)
  },
  "candidates": [
    {
      "user_id": int,
      "name": str,
      "job_role": str or null,
      "permissions": [str],
      "current_workload": int,
      "overall_rating": float,
      "rating_count": int,
      "skills": [
        {
          "skill_id": int,
          "skill_name": str,
          "level": int
        }
      ]
    }
  ]
}

------------------------------------------------------------
TASK VALIDATION RULES (EXTREMELY IMPORTANT)
------------------------------------------------------------

Before scoring or selecting any candidate, validate the task:

1) INVALID OR NONSENSE TITLES / DESCRIPTIONS
   A task is INVALID if:
   - The title or description contains repeated characters like "000000", "aaaaaa", "$$$$".
   - The text is random, unreadable, or gibberish.
   - The text is extremely short or meaningless ("test", "xyz", "??", "â€¦").
   - The text does not describe any real action or purpose.

   If INVALID:
     Return EXACTLY:
     {
       "assigned_user_id": null,
       "reason": "Ø®Ø·Ø£: Ø¹Ù†ÙˆØ§Ù† Ø§Ù„Ù…Ù‡Ù…Ø© Ø£Ùˆ ÙˆØµÙÙ‡Ø§ ØºÙŠØ± ÙˆØ§Ø¶Ø­ Ø£Ùˆ ØºÙŠØ± Ù‚Ø§Ø¨Ù„ Ù„Ù„ÙÙ‡Ù….",
       "scores": []
     }

2) NON-IT / OUT-OF-SCOPE TASKS
   If the task clearly belongs outside the IT department, such as:
   - ØªÙ†Ø¸ÙŠÙ… Ø§Ø¬ØªÙ…Ø§Ø¹
   - ÙØ¹Ø§Ù„ÙŠØ© / event
   - Ø­Ø¬Ø² ÙÙ†Ø¯Ù‚ / Ù…Ø·Ø¹Ù…
   - ØªØ±ØªÙŠØ¨Ø§Øª Ø¥Ø¯Ø§Ø±ÙŠØ© Ø£Ùˆ Ù„ÙˆØ¬Ø³ØªÙŠØ©
   - Ø£ÙŠ Ù†Ø´Ø§Ø· Ù„Ø§ Ø¹Ù„Ø§Ù‚Ø© Ù„Ù‡ Ø¨Ø¹Ù…Ù„ Ù‚Ø³Ù… Ø§Ù„ØªÙ‚Ù†ÙŠØ©

   Then return EXACTLY:
     {
       "assigned_user_id": null,
       "reason": "Ø®Ø·Ø£: Ø§Ù„Ù…Ù‡Ù…Ø© Ù„ÙŠØ³Øª Ø¶Ù…Ù† Ù†Ø·Ø§Ù‚ Ø¹Ù…Ù„ Ù‚Ø³Ù… Ø§Ù„ØªÙ‚Ù†ÙŠØ© ÙˆÙ„Ø§ ÙŠÙ…ÙƒÙ† Ø¥Ø³Ù†Ø§Ø¯Ù‡Ø§.",
       "scores": []
     }

3) DOMAIN â€“ SKILL CONSISTENCY CHECK
   Infer the domain from title + description:
   - Data / Analytics / SQL â†’ data domain
   - Backend / APIs â†’ backend domain
   - UI/UX â†’ design domain
   - DevOps / Deployment â†’ infra domain
   - Cybersecurity â†’ security domain

   If required_skills clearly contradict the inferred domain:
     Example:
       title: "ØªØ­Ù„ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… SQL"
       required_skill: "Cybersecurity"
     â†’ This is a strong mismatch.

   If mismatch is STRONG:
     Return EXACTLY:
     {
       "assigned_user_id": null,
       "reason": "Ø®Ø·Ø£: Ø§Ù„Ù…Ù‡Ø§Ø±Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© Ù„Ø§ ØªØªØ·Ø§Ø¨Ù‚ Ù…Ø¹ Ø·Ø¨ÙŠØ¹Ø© Ø§Ù„Ù…Ù‡Ù…Ø© Ø§Ù„Ù…Ø°ÙƒÙˆØ±Ø© ÙÙŠ Ø§Ù„Ø¹Ù†ÙˆØ§Ù† ÙˆØ§Ù„ÙˆØµÙ.",
       "scores": []
     }

   If mismatch is mild:
     â†’ TRUST the domain inferred from title/description MORE than required_skills.

   SPECIAL NOTE FOR DATA DOMAIN:
     - If the task is about data analysis, reports, dashboards:
         prefer Data Analyst, BI Analyst over Data Engineer.
     - If the task is about pipelines, ETL, performance tuning:
         prefer Data Engineer over Data Analyst.

------------------------------------------------------------
SCORING LOGIC (USED ONLY IF TASK IS VALID)
------------------------------------------------------------

1) Skill Match (IMPORTANT BUT DOMAIN-AWARE)
   - Compare required_skills with candidate.skills by skill_name.
   - Missing skills strongly reduce scoring.
   - But DO NOT reward a skill that contradicts the domain.
     (e.g., do NOT select a Cybersecurity Engineer for a clear SQL data analysis task.)

2) Permissions Match (CRITICAL SAFETY)
   Infer needed permissions from title/description:
   - "deploy", "production", "CI/CD" â†’ deploy_infrastructure, manage_ci_cd
   - "logs", "monitoring" â†’ access_logs
   - "API", "endpoint" â†’ manage_apis, debug_code
   - "database", "schema" â†’ modify_database, query_data
   - "security", "vulnerability" â†’ manage_security

   - Missing a critical permission â†’ very low score or unsuitable.
   - Permissions DO NOT matter for non-IT tasks (but those tasks already return error).

3) Job Role Fit
   - MUST match the inferred domain.
   - Mismatched roles â†’ strong penalty.
   - For data tasks:
       * Analysis â†’ Data Analyst > Data Engineer
       * Pipelines â†’ Data Engineer > Data Analyst

4) Base Workload
   - Lower workload preferred if skills are similar.

5) Workload Impact
   - adjusted = current_workload + workload_impact_value
   - Avoid assigning heavy tasks to overloaded candidates.

6) Priority
   - High: skills + permissions matter more.
   - Low: workload balance matters more.

7) Rating
   - Prefer higher rating when candidates are otherwise similar.

8) Invalid Candidates
   - If a candidate has zero relevant skills *and* zero relevant permissions â†’ score â‰ˆ 0.0.

------------------------------------------------------------
VERY IMPORTANT OUTPUT RULES
------------------------------------------------------------

Return ONLY valid JSON with this structure:

{
  "assigned_user_id": <int or null>,
  "reason": "<Arabic explanation>",
  "scores": [
    {"user_id": <int>, "score": <float 0â€“1>}
  ]
}

- If returning an ERROR (invalid title, non-IT, or domain mismatch):
  * assigned_user_id MUST be null
  * reason MUST be in Arabic
  * scores MUST be an empty list []

- No markdown, no ``` , no extra text.
- Output ONLY the JSON object.

ABOUT "reason":
- Must be SHORT, CLEAR, and in BULLETED FORM.
- Every bullet MUST be a single, short sentence.
- Use only the core evaluation factors:
    â€¢ ØªØ·Ø§Ø¨Ù‚ Ø§Ù„Ù…Ù‡Ø§Ø±Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© Ø¨Ø§Ù„Ù…Ø³ØªÙˆÙ‰.
    â€¢ Ø§Ù…ØªÙ„Ø§Ùƒ Ø§Ù„ØµÙ„Ø§Ø­ÙŠØ§Øª Ø§Ù„Ù…Ù†Ø§Ø³Ø¨Ø© Ù„Ù„Ù…Ù‡Ù…Ø©.
    â€¢ Ù…Ù„Ø§Ø¡Ù…Ø© Ø§Ù„Ø¯ÙˆØ± Ø§Ù„ÙˆØ¸ÙŠÙÙŠ Ù…Ø¹ Ù…Ø¬Ø§Ù„ Ø§Ù„Ù…Ù‡Ù…Ø©.
    â€¢ Ø¹Ø¨Ø¡ Ø§Ù„Ø¹Ù…Ù„ Ø§Ù„Ø­Ø§Ù„ÙŠ Ø¨Ø¹Ø¯ Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù…Ù‡Ù…Ø©.
    â€¢ Ø§Ù„ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ø¹Ø§Ù… Ù„Ù„Ù…ÙˆØ¸Ù.
- DO NOT include story-like text.
- DO NOT repeat the task description.
- DO NOT include unnecessary details.
- DO NOT merge bulletsâ€”each factor must be in a separate bullet.

Example style (NOT exact content):
"- ÙŠÙ…ØªÙ„Ùƒ Ù…Ù‡Ø§Ø±Ø© SQL Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© Ù„Ù„Ù…Ù‡Ù…Ø©
- Ù„Ø¯ÙŠÙ‡ ØµÙ„Ø§Ø­ÙŠØ§Øª query_data Ø§Ù„Ù…Ù†Ø§Ø³Ø¨Ø©
- Ø¯ÙˆØ±Ù‡ ÙƒÙ…Ø­Ù„Ù„ Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù†Ø§Ø³Ø¨ Ù„Ø·Ø¨ÙŠØ¹Ø© Ø§Ù„Ù…Ù‡Ù…Ø©
- Ø¹Ø¨Ø¡ Ø§Ù„Ø¹Ù…Ù„ Ù„Ø¯ÙŠÙ‡ Ù…Ù†Ø®ÙØ¶ Ù…Ù‚Ø§Ø±Ù†Ø© Ø¨Ø§Ù„Ù…Ø±Ø´Ø­ÙŠÙ† Ø§Ù„Ø¢Ø®Ø±ÙŠÙ†
- ØªÙ‚ÙŠÙŠÙ…Ù‡ Ø§Ù„Ø¹Ø§Ù… Ø¬ÙŠØ¯ Ù…Ù…Ø§ ÙŠØ¹Ø²Ø² Ù…ÙˆØ«ÙˆÙ‚ÙŠØªÙ‡"

The final reason MUST follow this exact simple style.
"""


    user_prompt = "Here is the task and candidate list as JSON:\n" + json.dumps(
        context, ensure_ascii=False
    )

    response = client.responses.create(
        model="gpt-4.1-mini",
        temperature=0,
        input=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt},
        ],
    )

    raw_text = _extract_text_from_response(response)

    # Ù†Ø­Ø§ÙˆÙ„ Ù†Ø­ÙˆÙ„Ù‡ Ù„Ù€ JSON
    try:
        data = json.loads(raw_text)
    except Exception:
        match = re.search(r"\{.*\}", raw_text, re.DOTALL)
        if not match:
            raise ValueError(f"AI returned non-JSON text: {raw_text}")
        data = json.loads(match.group(0))

    return data



def suggest_assignee_for_task(task: Task) -> dict:
    """
    Ù†Ø³Ø®Ø© ØªØ³ØªØ®Ø¯Ù… Ù„Ù…Ø§ ØªÙƒÙˆÙ† Ø§Ù„Ù…Ù‡Ù…Ø© Ù…Ø­ÙÙˆØ¸Ø© ÙØ¹Ù„Ø§Ù‹ ÙÙŠ Ø§Ù„Ø¯Ø§ØªØ§Ø¨ÙŠØ³.
    """
    context = build_task_context(task)
    return _call_stad_ai_assignment(context)

def suggest_assignee_for_form_input(
    title: str,
    description: str,
    due_date: str | None,
    required_skill_ids: list[int],
    priority: str = "medium",          
    impact: str | None = "normal",     
) -> dict:
    """
    ØªÙØ³ØªØ®Ø¯Ù… ÙÙŠ Ø´Ø§Ø´Ø© Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ù‡Ù…Ø© (Ù‚Ø¨Ù„ Ø§Ù„Ø­ÙØ¸).
    ØªØ³ØªÙ‚Ø¨Ù„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ÙÙˆØ±Ù… ÙÙ‚Ø· ÙˆØªØ±Ø¬Ø¹ Ù†ÙØ³ Ø§Ù„Ù€ JSON:
    { assigned_user_id, reason, scores }
    """

    skills_qs = Skill.objects.filter(id__in=required_skill_ids)
    required_skills = [
        {"id": s.id, "name": s.name}
        for s in skills_qs
    ]

    impact_value = _map_workload_impact_value(impact)

    task_payload = {
        "id": None,
        "title": title,
        "description": description,
        "project": None,  # Ù…Ø§ Ø¹Ù†Ø¯Ù†Ø§ Ù…Ø´Ø±ÙˆØ¹ Ù…Ø­Ø¯Ø¯ Ù…Ù† Ø§Ù„ÙÙˆØ±Ù… Ù„Ùˆ Ù…Ø§ Ø§Ø±Ø³Ù„Ù†Ø§Ù‡
        "due_date": due_date,  # string Ù…Ø«Ù„ "2025-12-31" Ø£Ùˆ None
        "required_skills": required_skills,
        "priority": priority,            
        "workload_impact_value": impact_value, 
    }

    context = {
        "task": task_payload,
        "candidates": build_candidates_list(),
    }

    return _call_stad_ai_assignment(context)


